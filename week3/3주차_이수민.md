# Troubleshooting

모델 구현 시, 원리 이해나 핵심 구현보다 debugging, tuning에 더 많은 시간을 쓰게 된다. (참 슬픈 일이다,,)

논문 상의 모델 성능과 실제 구현한 모델의 성능이 다른 이유는 다음과 같다.

- implementation bug
- hyperparameter choice
- data choice
- dataset construction

<br>

# Strategy

그나마 체계적으로 모델을 학습시켜 디버깅을 쉽게하기 위한 전략: start simple → implement/debug → evaluate → hyperparameter tune/improve

<br>

## 1. Start simple

### Simple architecture

- image data를 다룰 경우, LeNet-like architecture으로 시작 → Resnet 등으로 완성
- sequence data를 다룰 경우, LSTM으로 시작 → attention model 등으로 완성
- 아래처럼 간단한 Fully-Connected network를 이용

<img src="https://scandalous-kite-212.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fd6312870-3475-4ff6-b32d-a9e550887220%2FUntitled.png?table=block&id=51eb2a7d-83c7-482c-a0f9-749bc54d8753&spaceId=b7f96bd1-e371-4bf4-aea6-b26a89e30e7c&width=1430&userId=&cache=v2" alt="multimodal simple architecture" width="600" height="300"/>

### Recommended Defaults

- optimizer: Adam (lr=3e-4)
- activations: **ReLU** in FC/Conv, **tanh** in LSTM
- initialize: **He et al.** normal in ReLU, **Glorot** normal in tanh
- regularize/data normalize: None, b/c bugs

### Normalize inputs

mean, variance 이용하거나, image의 경우 255로 나누는 것으로, 직접 input을 normalize해야 한다. 

normalize library를 믿지 말 것.

 <br>

## 2. Implement/Debug

### Write bug-free code

가장 많이 발생하는 버그는 다음과 같다.

→ incorrect shape, no normalization, wrong loss function, omitting train/eval mode, inf/Nan

### Overfit single batch

batch size를 고정한 상태에서, loss를 줄이는 방식으로 모델을 훈련한다. 만약 loss가 원하는 만큼 나오지 않는다면 다음 항목들을 확인하자.

- error goes up/explodes: learning rate↑, numerical issue
- error oscillates: corrupted data/labels
- error plateaus: learning rate↓, too much regularization, incorrect input to loss function

### Compare to Known Result

현재 사용 중인 dataset을 이용한 공식 model 구현 결과와 비교하는 것이 가장 좋다. 

상황이 여의치 않을 경우, benchmark dataset을 이용한 model의 구현 결과와 비교하여, 평균 정도의 성능이 나오는지 알아보자.

<br>

## 3. Evaluate

test error = irreducible error(human level) + variance + bias + distribution shift + val overfitting이라 생각할 수 있다.

따라서 test error가 높을 때 고려해야 하는 것은, 

- bias-variance tradeoff: variance가 높을수록 trainset에 overfit하고 bias가 높을수록 underfit

<img src="https://user-images.githubusercontent.com/102659829/161081877-a4e36711-2602-4336-bf64-e38eb6cbcfdb.png" alt="bias-variance tradeoff" width="600" height="300"/>

- distribution shift: train dataset과 test dataset의 분포가 애초에 달라서 생기는 차이

<br>

## 4-1. Improve model/data

underfit, overfit, distribution shift 순서로 해결하는 것이 좋다.

| Error              | 해결방법                                                     |
| ------------------ | ------------------------------------------------------------ |
| underfit           | make model bigger(add layers), reduce regularization 순으로 시도 |
| overfit            | add train data, add normalization, add data augmentation, increase regularization 순으로 시도 |
| distribution shift | train dataset과 test dataset의 차이를 눈으로 직접 확인한 뒤, test set과 비슷한 데이터를 더 수집하거나 기존의 데이터에 그 차이를 합성하는 방식을 사용한다. |

<br>

## 4-2. Tune hyperparameters

hyperparameter 수가 많을 경우, model에 미치는 영향이 큰, *more-sensitive*한 순서로 최적화한다.

<img src="https://scandalous-kite-212.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F42671337-2a5d-4916-ab6b-d6c06b82e1a6%2FUntitled.png?table=block&id=2f6ee509-7905-4ad9-a36e-aa19da61d6de&spaceId=b7f96bd1-e371-4bf4-aea6-b26a89e30e7c&width=1430&userId=&cache=v2" alt="hyperparameter sensitive level" width="300" height="300"/>

hyperparameter optimization 방법에는 

- Manual/Bayesian hyperparameter optimization, Grid/Random search, ...
- 가장 많이 쓰이는 방식은 coarse-to-fine.
  - 처음에는 무작위로 큰 범위를 잡고, 결과에 따라 범위를 좁혀나가며 최적의 하이퍼파라미터를 찾는다.

<img src="https://user-images.githubusercontent.com/102659829/161093525-6a6ff4a7-eac6-49d2-922a-4bbe14988025.png" alt="coarse-to-fine" width="300" height="300" />

